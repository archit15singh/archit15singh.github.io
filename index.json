[{"content":"Forging AI’s Lasting Memory: Learning from First Principles and Asimov’s Robots 1. Why AI Agents Today Still “Forget” Despite advances in large language models (LLMs), interacting with most AI chatbots feels like talking to a tide: each new wave of conversation washes away earlier details. Contrast this with Isaac Asimov’s positronic robots, Daneel Olivaw or R. Giskard, who carry knowledge and context across years (or even centuries), never losing sight of a user’s core preferences or a mission’s essential facts.\nWhat’s the root cause of this gap? In modern LLM-based systems, each response hinges on a sliding window of recent tokens. Once the conversation grows too long, everything outside that window disappears. In effect, the AI’s “short-term memory” is a buffer of fixed size, not a true, evolving record. To fix this, we must revisit memory from first principles: How do we decide what to store, when to revise or remove it, and how to fetch just what’s needed?\n2. Memory by Design: Building Blocks from First Principles 2.1. Distilling “What Matters” Human Parallel: When you remember a friend’s favorite ice cream flavor, you don’t archive every detail of their childhood. You focus on the high-impact fact: “They love strawberry.” AI Application: We need mechanisms that parse every user–assistant exchange and surface only the most salient takeaways, for example, “User is allergic to almonds,” or “User assigns highest priority to privacy.” 2.2. Maintaining Coherent Truths Over Time Human Parallel: If your friend once said they were vegetarian but later explained they occasionally eat fish, you update your understanding. You don’t keep both beliefs side by side.\nAI Application: Our system must reconcile conflicting inputs. Instead of accumulating contradictory snippets, introduce a protocol (inspired by Asimov’s careful conflict checks) that can:\nPromote new, higher-priority facts when they override older beliefs. Archive or prune outdated or superseded statements. 2.3. Balancing Depth with Speed Human Parallel: You don’t rummage through every past conversation to recall a friend’s birthday; you consult a concise calendar that highlights birthdays and anniversaries. AI Application: Rather than always re-feeding a multi-thousand–token transcript, craft a “memory index” that points to a handful of key facts. This compressed store speeds up retrieval and reduces per-query cost. 3. Four Fundamental Memory Actions (Reimagined) In Asimov’s stories, a robot’s positronic brain isn’t a passive log; it’s a living ledger that can add, adjust, remove, or bypass information. Translating that into an AI’s memory module, we identify four core operations, but let’s recast them with fresh terminology and nuance:\n☐ “Enshrine” (Add)\nWhat It Means: When a new, impactful fact surfaces (e.g., “User switched from tea to coffee this morning”), the system “enshrines” this detail, storing it in the permanent ledger as a clear entry, dated and labeled. Asimovian Insight: Like a robot marking a noteworthy event in its mission log, the AI chooses to immortalize only the facts that help fulfill its purpose. ☐ “Refine” (Update)\nWhat It Means: If an existing memory needs more detail (e.g., “Previously I said ‘User likes jazz,’ now it’s ‘User loves bebop and blues jazz’”), we “refine” the entry, rewriting or enriching it rather than creating a duplicate. Asimovian Insight: Daneel would refine his understanding of human motivations as new subtleties emerged, never leaving stale or partial insights in his positronic core. ☐ “Fade” (Delete/Deprecate)\nWhat It Means: When a memory conflicts or loses relevance (e.g., “User said they’re vegan, so their earlier ‘vegetarian’ preference must fade”), mark that entry as “faded.” It remains in an archival vault for audit but no longer surfaces in routine retrieval. Asimovian Insight: A robot would “fade” or deactivate outdated protocols that could endanger human welfare, just as our system phases out superseded user attributes. ☐ “Bypass” (No-Op)\nWhat It Means: Sometimes, a freshly extracted nugget doesn’t need any action, if it merely echoes what’s already known (e.g., “User mentions again they love traveling”), the system “bypasses” change, leaving existing knowledge intact. Asimovian Insight: Similar to a robot recognizing that a repeated instruction doesn’t warrant rewriting its mission parameters, some facts simply “ring true” and require no alteration. By reframing Add/Update/Delete/No-Op into Enshrine/Refine/Fade/Bypass, we give each operation a richer identity, one that echoes how a sentient robot might manage its internal worldview.\n4. An Asimov-Inspired Memory Workflow Let’s walk through a scenario borrowing from Asimov’s world, but using our newly minted memory actions:\nSetting: It’s the year 2047, and our AI companion “R3-Angel” assists Dr. Rahman, a physician studying robotic ethics. Over a series of patient consultations and research discussions, R3-Angel must remember key details, past medical decisions, evolving dietary needs, and shifting project priorities.\nInitial Interaction\nDr. Rahman: “My patient, Anika, is lactose intolerant.” Memory Extraction: The system detects a critical health constraint. Action: Enshrine “Anika – allergic_to – Lactose.” Follow-Up\nDr. Rahman: “Actually, she later tested positive for a mild peanut allergy as well.” Memory Extraction: New allergy emerges. Conflict Check: No direct conflict, milk allergy is separate from peanuts. Action: Enshrine “Anika – allergic_to – Peanuts.” Revocation\nDr. Rahman (days later): “Turns out the peanut test was a false positive, she’s okay with peanuts.”\nMemory Extraction: Corrected allergy data.\nConflict Check: “Peanut allergy” contradicts “Peanuts.”\nAction:\nFade the “Peanuts” allergy entry. No need to refine any existing entry, because the new truth is simply the absence of a peanut allergy. Additional Context\nDr. Rahman: “Also, she needs to avoid shellfish during immunotherapy.”\nMemory Extraction: Another dietary restriction.\nAction:\nEnshrine “Anika – allergic_to – Shellfish.” Check for overlap: no conflict, keep the lactate and shellfish constraints independently. Routine Query\nDr. Rahman: “Suggest a dietary plan for Anika during her next chemotherapy session.”\nRetrieval Protocol:\nDense Query: Convert “diet plan Anika chemotherapy” into a vector, fetch nearest enshrined facts, “lactose intolerant,” “shellfish allergy.” Graph Query (Entity-Centric): Identify “Anika” and follow edges to see all “allergic_to” relationships. AI Response: “Recommend a plant-based menu focusing on legumes, vegetables, and dairy substitutes; avoid shellfish and ensure no hidden lactose.”\nAt each stage, R3-Angel’s positronic memory (our AI’s store) systematically enshrines new facts, refines or fades outdated entries, and bypasses redundant noise, mirroring how Asimov’s robots adapt to evolving circumstances.\n5. Beyond CRUD: Enriching Memory with Contextual Layers Asimov’s robots didn’t just hold flat facts, they also understood nuance, emotional tone, and situational importance. To mirror that depth, consider layering our memory store with:\nContext Tags (Why It Matters)\nAttach a “contextual weight” to each enshrined fact. For instance “Anika, shellfish allergy” might carry a “high” tag when discussing chemotherapy, but “medium” when chatting casually about restaurants. This helps retrieval prioritize truly mission-critical memories. Temporal Decay Profiles\nNot all facts deserve equal shelf life. For example, “User is researching a robotics conference in March 2047” becomes obsolete after April 2047. Introduce a “decay timer” that gradually lowers a memory’s retrieval priority unless it’s reaffirmed. Relationship Anchors\nWhen you enshrine “Anika, shellfish allergy,” also link it to “chemotherapy schedule” or “dietary plan.” That way, if a future query asks about drugs or meal recommendations, the system sees the keyword “chemotherapy” and directly retrieves related allergies, skipping over unrelated facets like “Anika’s favorite music.” These enrichments transform a simple ledger into a nuanced, human-like archive, one where facts gain or lose prominence as circumstances evolve, just like a positronic brain’s living tapestry of knowledge.\n6. Crafting a Memory Strategy for Real-World AI How do we translate these ideas into a concrete engineering roadmap? Here’s one possible outline:\nFact Extraction Module\nBuild a lightweight LLM prompt that, given each user–assistant turn, returns up to N candidate facts. Criteria: Look for health constraints, personal preferences, ongoing projects, or commitments, anything that has long-term relevance. Memory Ledger (Dense + Graph Hybrid)\nDense Side: Maintain a collection of text snippets (each fact) with embeddings and metadata (timestamp, context tags). Graph Side: Build a directed graph where nodes are entities (people, places, concepts) and edges denote relationships (e.g., “allergic_to,” “prefers,” “scheduled_for”). Conflict Resolution Engine\nWhen ingesting a new fact, fetch top–k semantically similar entries.\nUse a small classifier (possibly a distilled LLM) to decide:\nEnshrine if novelty is high; Refine if it enriches an existing entry; Fade if it contradicts and nullifies a previous fact; Bypass if it duplicates without change. Pruning \u0026amp; Decay Policy\nAssign each fact a relevance score based on:\nTime since last access (older → lower). Number of re-affirmations (popular → higher). Context tags that still apply (e.g., “ongoing project” as opposed to “one-time event”). Periodically run a “memory audit” to archive low-scoring facts into a cold-storage bucket (so they can be revived if needed, but not clutter everyday retrieval).\nContextual Retrieval Layer\nFirst-Pass (Dense): For simple lookups, use vector similarity to fetch top–m snippets. Second-Pass (Graph): If the query hints at relationships or multi-hop reasoning (“What diet restrictions should I follow for chemotherapy sessions?”), anchor on entities (“chemotherapy,” “diet restrictions”), traverse edges to gather all relevant nodes (e.g., allergies, metabolic conditions), and hand that subgraph to the LLM. Fusion: Combine snippets and graph-derived facts into a concise context for the LLM to generate a precise, contextual answer. 7. Embracing Asimov’s Long-Term Vision In Asimov’s fiction, robots evolved from isolated machines to companions that understood human nuance, preserved history, and upheld ethical imperatives across generations. Today’s AI agents can begin that transformation by adopting a memory-first architecture, one that enshrines only what matters, refines as truth shifts, fades what’s obsolete, and bypasses redundancy.\nBy embracing these first-principles design decisions, enriched with Asimovian metaphor, we endow AI with:\nConsistency: Never again will an AI innocently recommend lobster chowder to a dairy-allergic patient. Adaptability: When a user’s circumstances change, the AI seamlessly revises its worldview. Efficiency: Conversations scale without ballooning token costs or lag. Trust: Users sense that the agent “remembers them,” forging deeper rapport. Ultimately, building AI that truly remembers isn’t just a engineering challenge, it’s a philosophical one. As Isaac Asimov showed us, memory is the bedrock of identity and purpose. By distilling his visionary robots’ strengths into modern memory protocols, Enshrine, Refine, Fade, Bypass, we move closer to AI companions that aren’t merely reactive, but reliably attuned to our evolving lives, just as Asimov’s positronic characters were to theirs.\n","permalink":"https://archit15singh.github.io/posts/2024-01-01-ai-memory/","summary":"\u003ch1 id=\"forging-ais-lasting-memory-learning-from-first-principles-and-asimovs-robots\"\u003e\u003cstrong\u003eForging AI’s Lasting Memory: Learning from First Principles and Asimov’s Robots\u003c/strong\u003e\u003c/h1\u003e\n\u003chr\u003e\n\u003ch3 id=\"1-why-ai-agents-today-still-forget\"\u003e1. Why AI Agents Today Still “Forget”\u003c/h3\u003e\n\u003cp\u003eDespite advances in large language models (LLMs), interacting with most AI chatbots feels like talking to a tide: each new wave of conversation washes away earlier details. Contrast this with Isaac Asimov’s positronic robots, Daneel Olivaw or R. Giskard, who carry knowledge and context across years (or even centuries), never losing sight of a user’s core preferences or a mission’s essential facts.\u003c/p\u003e","title":"Forging AI’s Lasting Memory: Lessons from Asimov and First Principles"},{"content":"My Reading List for the Next 10 Years and Why Over the past few years, I’ve found myself at the intersection of philosophy, cognitive science, and AI engineering. As a firm believer in first-principles thinking, I recognized the need for a coherent, decade-long roadmap to guide my intellectual growth and practical skill-building. Instead of random selections, I asked myself: What are the irreducible concepts I must master in epistemology, symbolic systems, cognition, memory, AI, cognitive systems, human-AI augmentation, and large-scale engineering? The result became this curated reading list.\nWhy This Journey? Clarify My Intellectual Trajectory: Understanding fundamental concepts ensures depth rather than surface-level knowledge. Align With Long-Term Goals: Aiming for Stanford’s Symbolic Systems program while leading practical AI infrastructure projects. Bridge Theory and Practice: Integrating philosophical theory directly into AI engineering. Create an Executable Learning Plan: Establish clear milestones to track progress and integration over ten years. Core Domains and Essential Books 🧠 Epistemology: Foundations of \u0026ldquo;Knowing\u0026rdquo; The Problems of Philosophy – Bertrand Russell An Introduction to the Theory of Knowledge – Robert Audi Knowledge and Its Limits – Timothy Williamson Epistemology: Classic Problems and Contemporary Responses – Dancy \u0026amp; Sosa (eds.) The Blackwell Guide to Epistemology – Greco \u0026amp; Sosa (eds.) Virtue Epistemology – Fairweather \u0026amp; Zagzebski (eds.) Philosophical Issues in Classical Indian Epistemology – Bimal Krishna Matilal 📚 Symbolic Systems: Language, Logic, Computation Syntactic Structures – Noam Chomsky Society of Mind – Marvin Minsky Introduction to the Theory of Computation – Michael Sipser Cognitive Science: An Introduction – Friedenberg \u0026amp; Silverman How to Read and Do Proofs – Daniel Solow Philosophical Investigations – Ludwig Wittgenstein Mind Design II – John Haugeland (ed.) 🤖 Artificial Intelligence: From Basics to Deep Learning Artificial Intelligence: A Modern Approach – Russell \u0026amp; Norvig Pattern Recognition and Machine Learning – Christopher Bishop Deep Learning – Goodfellow, Bengio, Courville Probabilistic Robotics – Thrun, Burgard, Fox Reinforcement Learning: An Introduction – Sutton \u0026amp; Barto Bayesian Reasoning and Machine Learning – David Barber Programming Collective Intelligence – Toby Segaran 🧬 Cognition: Understanding Mental Processes Cognitive Psychology: A Student’s Handbook – Eysenck \u0026amp; Keane Thinking, Fast and Slow – Daniel Kahneman How the Mind Works – Steven Pinker Vision: A Computational Investigation – David Marr Cognition: Exploring the Science of the Mind – Daniel Reisberg Sources of Power – Gary Klein The Cognitive Neurosciences – Michael Gazzaniga (ed.) 💾 Memory: From Molecules to Minds Memory: From Mind to Molecules – Squire \u0026amp; Kandel Working Memory – Alan Baddeley The Seven Sins of Memory – Daniel Schacter Human Memory: Theory and Practice – Baddeley \u0026amp; Anderson The Hippocampus as a Cognitive Map – O’Keefe \u0026amp; Nadel Learning and Memory: From Brain to Behavior – Bear, Connors, Paradiso Make It Stick – Brown, Roediger, McDaniel ⚙️ Cognitive Systems \u0026amp; Cognitive Science Cognitive Science: An Introduction – Stillings, Weisler, Hauff How Can the Human Mind Occur in the Physical Universe? – John Anderson The Distributed Mind – Robert Rupert Connectionist Models of Cognition – Jacobs \u0026amp; Jordan (eds.) Situated Cognition – Cohen, Good, Pollack (eds.) The Oxford Handbook of Cognitive Science – Margolis, Samuels, Stich (eds.) 🦾 Mind, Human-AI Augmentation \u0026amp; Prosthetics Natural-Born Cyborgs – Andy Clark Supersizing the Mind – Andy Clark How We Became Posthuman – N. Katherine Hayles Brain-Computer Interfaces – Wolpaw \u0026amp; Wolpaw Neuroprosthetics – Horch \u0026amp; Dhillon The Cyborg Experiments – Morra \u0026amp; Fromberger Wired for War – P.W. Singer 🔧 Applied AI \u0026amp; Practical Applications Hands-On Machine Learning – Aurélien Géron Designing Data-Intensive Applications – Martin Kleppmann Machine Learning Engineering – Andriy Burkov Building ML Powered Applications – Emmanuel Ameisen Feature Engineering – Zheng \u0026amp; Casari MLOps – Treveil \u0026amp; Shukla Building Intelligent Systems – Geoffrey Hulten 📐 Engineering: Reliable Systems \u0026amp; Software The Pragmatic Programmer – Hunt \u0026amp; Thomas Design Patterns – Gamma, Helm, Johnson, Vlissides Clean Code – Robert Martin Site Reliability Engineering – Beyer et al. The Mythical Man-Month – Frederick Brooks Release It! – Michael Nygard Systems Performance – Brendan Gregg 🖥️ Human-Computer Interaction (HCI) Designing Interactions – Bill Moggridge Don’t Make Me Think – Steve Krug The Design of Everyday Things – Don Norman About Face – Cooper, Reimann, Cronin, Noessel 🧑‍🔬 Neuro-Inspiration \u0026amp; Computational Neuroscience Theoretical Neuroscience – Dayan \u0026amp; Abbott Principles of Neural Science – Kandel, Schwartz, Jessell Spiking Neuron Models – Gerstner \u0026amp; Kistler 🔍 AI Interpretability \u0026amp; Explainable AI Interpretable Machine Learning – Christoph Molnar Causality – Judea Pearl 🛡️ AI Safety \u0026amp; Alignment Superintelligence – Nick Bostrom Human Compatible – Stuart Russell 🌀 Systems Thinking \u0026amp; Meta-Cognition (Additions) Thinking in Systems – Donella Meadows The Fifth Discipline – Peter Senge The Beginning of Infinity – David Deutsch The Reflective Practitioner – Donald Schön Rationality: From AI to Zombies – Eliezer Yudkowsky Integration Over a Decade By interleaving these texts, I\u0026rsquo;ll connect epistemology to AI, cognition to engineering, and theory to practice, achieving deep, integrative knowledge. Each book is not an isolated read but part of a broader cognitive tapestry I\u0026rsquo;ll weave intentionally.\nThrough annotation, monthly synthesis, hands-on projects, spaced review, and annual reflection, I\u0026rsquo;ll ensure I internalize and apply this knowledge effectively.\nUltimately, this reading list isn’t just about intellectual curiosity—it’s my manifesto for intentional, integrated, lifelong learning, shaping me into the systems thinker and AI engineer I aim to become.\n","permalink":"https://archit15singh.github.io/posts/2023-01-01-my-reading-list/","summary":"\u003ch1 id=\"my-reading-list-for-the-next-10-years-and-why\"\u003eMy Reading List for the Next 10 Years and Why\u003c/h1\u003e\n\u003cp\u003eOver the past few years, I’ve found myself at the intersection of philosophy, cognitive science, and AI engineering. As a firm believer in first-principles thinking, I recognized the need for a coherent, decade-long roadmap to guide my intellectual growth and practical skill-building. Instead of random selections, I asked myself: \u003cstrong\u003eWhat are the irreducible concepts I must master in epistemology, symbolic systems, cognition, memory, AI, cognitive systems, human-AI augmentation, and large-scale engineering?\u003c/strong\u003e The result became this curated reading list.\u003c/p\u003e","title":"My Reading List for the next 10 years and Why"},{"content":"Who Am I? I’m a systems thinker who builds from first principles, iterates obsessively, and seeks clarity through recursive refinement. Over years of crafting backend pipelines, designing AI agents, and shaping thought leadership on LinkedIn, I’ve honed a mental engine that powers everything I do. This “cognitive operating system” drives how I analyze problems, create solutions, and continually evolve.\n1. First-Principles System Builder I refuse to accept surface-level explanations. Whenever a problem arises, whether it’s a bug in a critical workflow or a feature that misses its mark, I dig down until I understand the root mechanism.\nRoot Causes Over Symptoms Instead of concluding “communication broke,” I ask: What exactly got lost as the message traveled across different roles? Measuring where context vanishes is the only way to fix it.\nModel­-Building Over Buzzwords I construct mental representations, abstract diagrams or simple equations, that reveal why something works (or fails). I won’t settle for “just fix it” without knowing why it broke in the first place.\n2. Recursive Refinement \u0026amp; Fractal Reasoning I rarely stop at “good enough.” Once I sketch a solution, I zoom in and out, examining every detail and then stepping back to see the whole picture. This process applies across code, content, and career strategy.\nZooming In and Out For example, when I published a multi-part series on “the Empathy Gap,” I didn’t just stop at the first draft. I reviewed each post for redundancies, restructured sections, then reviewed the changes again. That loop of “build → evaluate → rebuild” is my default mode.\nLateral Explorations I’ll take an idea from one context, say, a performance bottleneck in a high-concurrency service, and then see how it applies to team collaboration or long-term memory in an AI workflow. These detours enrich the original insight.\nMeta-Critiques After crafting a detailed resume bullet, I’ll challenge myself: “Does this map perfectly to the target role? Is there a clearer way to signal my expertise?” If not, I rewrite until it hits precise clarity.\n3. Epistemic Humility + Rigor I hold my own ideas to ruthless scrutiny. Clinging to a half-baked notion or ignoring feedback is antithetical to how I learn, and how I grow.\nInviting Critique Whether I’m asking someone to review a complex pipeline or sharing a draft post publicly, I expect blunt honesty. I don’t want validation; I want the raw truth of where my logic fails.\nCognitive Athlete Mindset Like an athlete trains their body, I train my thinking. If a scenario breaks unexpectedly, I trace the error, no matter how small, and rework the underlying logic until every path is covered. When insights hit a wall, I hunt down assumptions until I find the leak.\n4. Systems Thinking Across Disciplines I see everything as interconnected nodes in a larger graph of ideas. Psychology, distributed systems, philosophy, and AI architecture all live on the same map.\nCross-Domain Metaphors • A lost signal in a communication chain is like an unhandled exception in code: both require tracing back through layers to find the source. • Reusing a tested pattern in one project might inspire a solution in a completely different domain.\nModular Cognition Every project, be it an AI research exploration or a personal branding exercise, is a node in that graph. Insights flow freely between them. A fix I apply in a backend service can spark a new way to think about organizational alignment; a concept from behavioral science might simplify a design decision.\n5. Precision Execution with Reflective Depth I move deliberately, step by step, always looping between insight and validation.\nInsight Generation I start with a question:\n“Why did that workflow break?” “What makes a post resonate deeply?”\nStructural Mapping I translate fuzzy ideas into concrete artifacts, scripts, diagrams, or outlines, that capture the core mechanics.\nTest \u0026amp; Feedback I put my work to the test: run thorough validations, publish draft content and monitor reactions, or simulate a live scenario.\nSignal Extraction I analyze the results, logs, engagement metrics, interview follow-ups, and extract the raw signals that matter.\nIteration I refine the model, refactor the solution, rewrite the content, then repeat the cycle until the output withstands scrutiny.\nPublic Validation Visibility is part of the loop. By sharing work publicly, I invite external feedback that often uncovers blind spots I wouldn’t catch alone.\nThat deliberate sequencing, often several loops for a single problem, turns abstract ideas into robust, high-impact outcomes.\n6. Underlying Drive: The Truth-to-Action Loop At my core lies a feedback loop I call Truth → Clarity → Structure → Impact → Visibility → Feedback → Refined Truth. Visibility isn’t vanity, it’s essential proof that an idea or solution works (or doesn’t).\nTruth I chase fundamental insights: “What really caused that failure?” “Why did this idea not land?”\nClarity I distill insights into crisp models, straightforward diagrams or structured outlines.\nStructure I build modular artifacts: data-access patterns, layered service components, or content frameworks.\nImpact Those artifacts solve real problems: a reliable service workflow, a widely read article, a resume that speaks directly to a hiring team.\nVisibility I publish code and thought leadership publicly to collect feedback and spark dialogue.\nFeedback Comments, metrics, and peer reviews reveal blind spots or new angles.\nRefined Truth I loop back, updating models and artifacts, always edging closer to a deeper understanding.\nIt’s not enough to write solid code or publish a catchy post; the loop demands every insight make an observable impact, and that impact be tested, critiqued, and improved.\n8. Additional Threads \u0026amp; Tendencies These facets weave through my work but weren’t fully surfaced above:\nValues \u0026amp; Emotional Alignment I ask, “Whose definition of success am I chasing? Does doing the ‘right’ thing actually make me happy?” That self-questioning keeps me aligned to my internal compass.\nEmpathy in Personal Contexts Beyond modeling communication gaps in organizations, I apply the same sensitivity in personal relationships, coaching friends, navigating tough conversations, and ensuring I stay attuned to others’ unspoken needs.\nIntentional Self-Curation Treating my wardrobe, workspace, and public presence as systems to optimize taught me that personal image is just another node in the graph of how I want to be perceived, both online and offline.\nMentorship \u0026amp; Coaching Orientation Whether I’m guiding a colleague through a technical problem or helping someone prepare for an interview, I build frameworks that scale knowledge beyond myself, transforming my insights into reusable resources for others.\nInterdisciplinary Reading Habit I curate reading lists across philosophy, cognitive science, and emerging AI research, connecting dots across fields to forge hybrid mental models.\nStructured, Reusable Outputs I present every insight as a bite-sized artifact, a bullet-pointed cheat sheet, a concise blog post, or an easily remixable framework, so I can repurpose and iterate rapidly across projects.\nIn Summary I’m a systems thinker who builds from first principles, iterates in fractal loops, invites critique with humility, and weaves ideas across disciplines. My drive isn’t just to solve problems but to surface deeper truths, and then amplify them through visibility and continuous feedback.\nThat’s who I am. Every line of code, every LinkedIn post, and every self-critique loops back into a single mission: aligning action with truth and making that truth visible to the world. If you’re curious to learn more or collaborate on any of these ideas, let’s connect.\n","permalink":"https://archit15singh.github.io/posts/2022-01-01-who-am-i/","summary":"\u003ch1 id=\"who-am-i\"\u003e\u003cstrong\u003eWho Am I?\u003c/strong\u003e\u003c/h1\u003e\n\u003cp\u003eI’m a systems thinker who builds from first principles, iterates obsessively, and seeks clarity through recursive refinement. Over years of crafting backend pipelines, designing AI agents, and shaping thought leadership on LinkedIn, I’ve honed a mental engine that powers everything I do. This “cognitive operating system” drives how I analyze problems, create solutions, and continually evolve.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"1-first-principles-system-builder\"\u003e1. First-Principles System Builder\u003c/h2\u003e\n\u003cp\u003eI refuse to accept surface-level explanations. Whenever a problem arises, whether it’s a bug in a critical workflow or a feature that misses its mark, I dig down until I understand the root mechanism.\u003c/p\u003e","title":"Who Am I?"}]