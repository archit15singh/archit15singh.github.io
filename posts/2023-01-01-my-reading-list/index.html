<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>My Reading List for the next 10 years and Why | Archit's Space</title><meta name=keywords content="Reading"><meta name=description content="A decade-long, first-principles roadmap through epistemology, symbolic systems, cognition, memory, AI, human-AI augmentation, and engineering—mapping the foundational texts that will shape my journey as a systems thinker and AI engineer."><meta name=author content="Archit Singh"><link rel=canonical href=https://archit15singh.github.io/posts/2023-01-01-my-reading-list/><link crossorigin=anonymous href=/assets/css/stylesheet.min.29b2809f521134e479bd6ede264ae1617ba99671b2d585b618a26aaededb3374.css integrity="sha256-KbKAn1IRNOR5vW7eJkrhYXuplnGy1YW2GKJqrt7bM3Q=" rel="preload stylesheet" as=style><link rel=icon href=https://archit15singh.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://archit15singh.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://archit15singh.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://archit15singh.github.io/apple-touch-icon.png><link rel=mask-icon href=https://archit15singh.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.147.7"><link rel=alternate hreflang=en href=https://archit15singh.github.io/posts/2023-01-01-my-reading-list/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="My Reading List for the next 10 years and Why"><meta property="og:description" content="A decade-long, first-principles roadmap through epistemology, symbolic systems, cognition, memory, AI, human-AI augmentation, and engineering—mapping the foundational texts that will shape my journey as a systems thinker and AI engineer."><meta property="og:type" content="article"><meta property="og:url" content="https://archit15singh.github.io/posts/2023-01-01-my-reading-list/"><meta property="og:image" content="https://archit15singh.github.io/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-01T12:00:00+00:00"><meta property="article:modified_time" content="2023-01-01T12:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://archit15singh.github.io/papermod-cover.png"><meta name=twitter:title content="My Reading List for the next 10 years and Why"><meta name=twitter:description content="A decade-long, first-principles roadmap through epistemology, symbolic systems, cognition, memory, AI, human-AI augmentation, and engineering—mapping the foundational texts that will shape my journey as a systems thinker and AI engineer."><meta name=twitter:site content="@https://twitter.com/archit_singh15"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://archit15singh.github.io/posts/"},{"@type":"ListItem","position":2,"name":"My Reading List for the next 10 years and Why","item":"https://archit15singh.github.io/posts/2023-01-01-my-reading-list/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"My Reading List for the next 10 years and Why","name":"My Reading List for the next 10 years and Why","description":"A decade-long, first-principles roadmap through epistemology, symbolic systems, cognition, memory, AI, human-AI augmentation, and engineering—mapping the foundational texts that will shape my journey as a systems thinker and AI engineer.","keywords":["Reading"],"articleBody":"My Reading List and Why Over the past few years, I’ve found myself at the intersection of philosophy, cognitive science, and cutting-edge AI engineering. As someone who believes deeply in first-principles thinking, I realized I needed a coherent roadmap, a decade-long syllabus, if you will, that would guide both my intellectual growth and practical skill building. Instead of randomly picking books, I asked myself: What are the irreducible concepts I must master in epistemology, symbolic systems, cognition, memory, AI, cognitive systems, human-AI augmentation, and large-scale engineering? The answer became this reading list.\nBelow, I explain the meta-purpose behind this journey, then break down each domain into its core pillars and list the highest-impact books that will serve as stepping stones over the next ten years.\nWhy I’m Doing This Clarify My Intellectual Trajectory I often remind myself: “Don’t accept surface-level explanations.” Whether I’m debugging a distributed system or diving into memory architectures for AI agents, I need to know why things work at a fundamental level. This reading list isn’t just a bibliography, it’s a scaffold that ensures every book I read builds on the ones before it.\nAlign With Long-Term Goals I’m targeting Stanford’s Symbolic Systems program and simultaneously leading AI-powered infrastructure projects. That means I need fluency in philosophical concepts like “justified belief” and hands-on expertise in deploying memory-augmented LLM pipelines. This dual pursuit of theory and practice shapes how I sequence these books.\nBridge Theory and Practice By approaching each field from first principles, I’ll see how epistemology informs probabilistic reasoning in AI or how cognitive-science insights shape my design of working-memory modules. I don’t want to treat theory and engineering as separate silos, I want them to feed into each other.\nCreate an Executable Learning Plan A decade seems long, but it can fly by if you wander aimlessly. By the end of year one, I should know the essentials of epistemology and basic symbolic computation. By year five, I’ll be integrating cognitive architectures with production-grade AI pipelines. By year ten, my hope is to ruminate on how self-reflexive AI agents can model their own “beliefs” and “memories.”\n1. Epistemology: Laying the Foundation for “Knowing” First Principles:\nKnowledge vs. Belief vs. Justification: What distinguishes “knowing” from merely “believing”? How do we justify our claims? Sources of Knowledge: Empiricism (sense data), Rationalism (logical inference), Pragmatism (utility), Coherentism (network of beliefs). Limits of Knowledge: Skepticism (can we know anything at all?), fallibilism (our beliefs can always be mistaken), contextualism (knowledge claims shift with context). Epistemic Norms: How do we evaluate evidence? When is a belief “justified”? How do we handle defeaters and counterexamples? My Ten-Year Book Sequence:\nBertrand Russell – The Problems of Philosophy (1912) An accessible primer on “what is knowledge?” and why skepticism isn’t just a parlor game. Russell’s clarity lays the groundwork before diving into denser analyses.\nRobert Audi – An Introduction to the Theory of Knowledge (2003) A systematic, classroom-style survey of belief, justification, and sources of knowledge. This text cements my grasp of key terminology and contrasts major schools of thought.\nTimothy Williamson – Knowledge and Its Limits (2000) Challenges the classical “justified true belief” model, treating knowledge as a basic mental state. Williamson’s arguments push me to confront contemporary debates head-on.\nJonathan Dancy \u0026 Ernest Sosa (eds.) – Epistemology: Classic Problems and Contemporary Responses (2010) A curated anthology of landmark papers, Gettier, Goldman, Nozick, that each reframe a central problem. Reading them slowly, I’ll trace how foundational debates evolved.\nJohn Greco \u0026 Ernest Sosa (eds.) – The Blackwell Guide to Epistemology (1999) Surveys subfields like social epistemology, virtue epistemology, and reliabilism. After Audi and Williamson, this volume shows how modern branches branched out.\nAbrol Fairweather \u0026 Linda Zagzebski (eds.) – Virtue Epistemology: Essays on Epistemic Virtue and Responsibility (1998) Focuses on intellectual character traits, humility, curiosity, and how they shape knowledge production. This helps me connect theory to everyday inquiry.\nBimal Krishna Matilal – Philosophical Issues in Classical Indian Epistemology (1986) Broadens my perspective with non-Western pramāṇa theory: perception (pratyakṣa), inference (anumāna), testimony (śabda). I’ll learn alternative conceptions of knowledge.\n2. Symbolic Systems: Understanding Language, Logic, and Computation First Principles:\nSymbolic Representation: How do discrete tokens, words, logical predicates, neural activations, encode meaning? Computation Over Symbols: The Church-Turing thesis, automata theory, and the notion that “cognition is computation.” Language as Structured Symbols: Syntax, semantics, and pragmatics; generative grammars (Chomsky) versus usage-based models. Cognition via Symbol Manipulation: Production systems (ACT-R, SOAR) and mental architectures that simulate symbol processing. Interdisciplinary Fusion: Blending philosophy, linguistics, computer science, psychology, and neuroscience into a cohesive framework. My Ten-Year Book Sequence:\nNoam Chomsky – Syntactic Structures (1957) Introduces generative grammar and formalizes how a finite set of rules can produce infinite sentences. Essential for modeling human language symbolically.\nMarvin Minsky – Society of Mind (1986) Argues that mind emerges from interactions of simple agents. It bridges symbolic and connectionist views and shows how modular subunits create higher-level behavior.\nMichael Sipser – Introduction to the Theory of Computation (2nd ed., 2005) Covers automata, formal languages, and Turing machines, ground zero for understanding “what can be computed.” Necessary before tackling computational models of cognition.\nJay Friedenberg \u0026 Gordon Silverman – Cognitive Science: An Introduction to the Science of the Mind (3rd ed., 2017) A broad survey of psychology, linguistics, AI, and neuroscience. It reveals how symbolic-systems thinkers integrate multiple perspectives.\nDaniel Solow – How to Read and Do Proofs (2012) Teaches me to parse dense mathematical arguments and construct my own proofs. If I’m going to engage with formal semantics or computational complexity, these tools are indispensable.\nLudwig Wittgenstein – Philosophical Investigations (1953) Challenges the notion that meaning reduces to formal rule-following. Wittgenstein’s thought experiments force me to question how symbols “mean” anything in real life.\nJohn Haugeland (ed.) – Mind Design II: Philosophy, Psychology, Artificial Intelligence (1997) A collection of essays on “designing” a mind in theory and practice. It aligns closely with Stanford’s Symbolic Systems teaching, weaving philosophy, AI, and psychology into a cohesive narrative.\n3. Artificial Intelligence: From Search to Deep Learning First Principles:\nSearch \u0026 Optimization: Many intelligent behaviors reduce to exploring a state space guided by heuristics. Knowledge Representation \u0026 Reasoning: Symbolic (logic, frames) vs. subsymbolic (neural embeddings); how we encode information. Machine Learning Fundamentals: Classical statistical models → representation learning → deep networks. Probabilistic Inference: Bayesian networks, Markov decision processes, modeling uncertainty in real environments. Reinforcement Learning \u0026 Planning: Agents learn via rewards or plan via tree search; the tension between model-based and model-free approaches. Embodiment \u0026 Robotics: Physical agents interacting with a world need perception, control, and real-time learning. My Ten-Year Book Sequence:\nStuart Russell \u0026 Peter Norvig – Artificial Intelligence: A Modern Approach (4th ed., 2020) The canonical AI textbook. I’ll read it in sequence: search → logic → probabilistic models → learning → RL → robotics, building from basics to sophistication.\nChristopher Bishop – Pattern Recognition and Machine Learning (2006) Focuses on probabilistic graphical models, kernel methods, and the EM algorithm. I need this statistical foundation before delving into neural networks.\nIan Goodfellow, Yoshua Bengio, \u0026 Aaron Courville – Deep Learning (2016) Provides a comprehensive overview of neural architectures, optimization, and theory. Reading this after Bishop sharpens my understanding of how classical methods evolved into deep nets.\nSebastian Thrun, Wolfram Burgard, \u0026 Dieter Fox – Probabilistic Robotics (2005) Embodied AI: SLAM, particle filters, and Kalman filters. If I ever build real-world agents, this book will be indispensable.\nRichard Sutton \u0026 Andrew Barto – Reinforcement Learning: An Introduction (2nd ed., 2018) The definitive text on RL: dynamic programming, Monte Carlo methods, TD learning, function approximation. Crucial for constructing memory-augmented agents that solve sequential tasks.\nDavid Barber – Bayesian Reasoning and Machine Learning (2012) Delves deeper into variational inference, sampling, and Bayesian methods. It complements probabilistic chapters in Russell \u0026 Norvig and Bishop.\nToby Segaran – Programming Collective Intelligence (2007) A hands-on guide to building recommenders, clustering algorithms, and classifiers in Python. I’ll use it to prototype quick, tangible demos, bridging theory and practice.\n4. Cognition: How Minds Process Information First Principles:\nInformation Processing Model: The brain is a system that takes input (perception), transforms it (attention, working memory), and outputs decisions or actions. Modularity vs. Distributed Processing: Are cognitive functions housed in specialized modules or emerging from distributed networks? Marr’s Tri-Level Analysis: Studying tasks at the computational (what problem is being solved?), algorithmic (how is it solved?), and implementational (how does neural hardware implement it?) levels. Mental Representations: Symbolic vs. connectionist, mental imagery vs. conceptual schemas. Decision-Making \u0026 Heuristics: How humans choose under bounded rationality, dual-process theories (System 1 vs. System 2). My Ten-Year Book Sequence:\nMichael Eysenck \u0026 Mark Keane – Cognitive Psychology: A Student’s Handbook (7th ed., 2015) A thorough survey of perception, attention, memory, language, and reasoning. It provides the empirical groundwork to compare AI models against human benchmarks.\nDaniel Kahneman – Thinking, Fast and Slow (2011) Explores System 1 (fast, intuitive) vs. System 2 (slow, deliberative) processes. Whenever I design algorithms that mimic, or correct, human decision-making, I’ll return to Kahneman.\nSteven Pinker – How the Mind Works (1997) Uses evolutionary psychology to explain perception, language, and reasoning. It helps me see why certain AI architectures might reflect (or deliberately deviate from) our evolutionary heritage.\nDavid Marr – Vision: A Computational Investigation into the Human Representation and Processing of Visual Information (1982) Marr’s classic on vision breaks down image processing at computational, algorithmic, and implementational levels. It sets a template for analyzing any cognitive task.\nDaniel Reisberg – Cognition: Exploring the Science of the Mind (6th ed., 2018) A modern, experiment-driven account of memory, attention, language, and problem solving. Its up-to-date findings guide my understanding of how to build AI that aligns with human tendencies.\nGary Klein – Sources of Power: How People Make Decisions (1998) Examines real-world experts (firefighters, pilots) making split-second decisions. If my future agents need to operate under stress, Klein’s work teaches how humans succeed, or fail, in critical scenarios.\nMichael S. Gazzaniga (ed.) – The Cognitive Neurosciences (6th ed., 2018) An anthology on neural mechanisms underlying cognitive processes: attention networks, working-memory circuits, decision-making pathways. I’ll use it as a reference whenever I delve into brain-inspired approaches.\n5. Memory: From Molecules to Minds First Principles:\nEncoding → Storage → Retrieval: The stages of memory: input gets held in working memory, consolidates into long-term storage, and later gets retrieved. Long-Term Memory Types: Declarative (episodic vs. semantic) vs. nondeclarative (procedural, priming). Neural Mechanisms: Hippocampus vs. neocortex, synaptic plasticity (LTP/LTD), and how memories stabilize over time. Working Memory Models: Baddeley’s multicomponent model, phonological loop, visuospatial sketchpad, central executive. Forgetting \u0026 Interference: Theories on decay, retrieval failure, proactive vs. retroactive interference. My Ten-Year Book Sequence:\nLarry Squire \u0026 Eric Kandel – Memory: From Mind to Molecules (1999) Connects cognitive behavioral experiments with cellular and molecular neuroscience. Early on, I’ll map high-level memory phenomena onto biological substrates.\nAlan Baddeley – Working Memory (2007) Details the multicomponent model and its experimental basis. Essential for designing AI “memory buffers” that approximate human capacity constraints.\nDaniel Schacter – The Seven Sins of Memory (2001) Describes real-world memory failures, transience, misattribution, suggestibility. When building memory-driven agents, I’ll refer to this to anticipate analogous “AI pitfalls.”\nAlan Baddeley \u0026 Michael Anderson – Human Memory: Theory and Practice (2nd ed., 2000) Combines theory with practical applications (e.g., spaced repetition). I’ll mine it for strategies (mnemonics, retrieval practice) that inform how to manage retention in large contexts.\nJohn O’Keefe \u0026 Lynn Nadel – The Hippocampus as a Cognitive Map (1978) Introduces place cells and spatial memory. This work inspires me to think about embedding “episodic context” in an agent’s memory system.\nMark Bear, Barry Connors, \u0026 Michael Paradiso – Learning and Memory: From Brain to Behavior (2nd ed., 2006) Integrates molecular/cellular mechanisms with overt behavior. I’ll align my ML architectures (e.g., synaptic-like weight updates) with real neural processes.\nPeter C. Brown, Henry L. Roediger III, \u0026 Mark A. McDaniel – Make It Stick: The Science of Successful Learning (2014) Distills memory research into practical strategies (retrieval practice, spacing). Since I need to internalize dozens of books over ten years, I’ll apply these techniques to retain and interleave concepts effectively.\n6. Cognitive Systems \u0026 Cognitive Science: Integrating Mind, Brain, and Environment First Principles:\nInterdisciplinary Integration: Cognitive science blends computer science (formal models), psychology (behavioral experiments), neuroscience (brain data), linguistics (language structure), and philosophy (conceptual analysis). Computational Models of Cognition: Architectures like ACT-R, SOAR, and connectionist neural networks; each embodies a different theory of how mental processes operate. Embodied \u0026 Situated Cognition: Cognition arises from continuous interaction with the environment, mind is not a “brain in a vat.” Cognitive Architectures: Unified frameworks (ACT-R, Soar) that simulate broad cognitive tasks under a single theoretical umbrella. Human-Computer Interaction \u0026 AI Integration: How humans and machines co-adapt, key for designing AI tools that “think” in human-useful ways. My Ten-Year Book Sequence:\nNeil Stillings, Steven Weisler, \u0026 Christopher Hauff – Cognitive Science: An Introduction (4th ed., 2018) A broad survey of core topics (perception, language, reasoning) with computational emphasis. Early on, I’ll use it to see how all the pieces connect.\nJohn R. Anderson – How Can the Human Mind Occur in the Physical Universe? (2007) A deep dive into ACT-R: how modules (memory retrieval, problem solving) fit together. I’ll study it to understand how a working cognitive architecture is constructed.\nRobert D. Rupert – The Distributed Mind: Achieving High-Level Cognition through Interactions between the Brain, Body, and World (2004) Argues for embodied cognition, the mind extends beyond neurons into the body and world. It shapes how I think about building agents that “live” in an environment.\nPhilippe Jacobs \u0026 Michael Jordan (eds.) – An Introduction to Connectionist Models of Cognition (1993) A collection of neural network models showing how subsymbolic processing can simulate cognitive tasks. It helps me compare symbolic (ACT-R) vs. subsymbolic approaches.\nKlaus Mainzer – Cognitive Systems and Neuroscience: The Conceptual Foundations of Neurophysics (2002) Explores mathematical and philosophical foundations of modeling cognitive processes in physical systems. I’ll focus on chapters showing how high-level cognitive theories map onto neural substrates.\nPhilip R. Cohen, Jerry A. Good, \u0026 James G. Pollack (eds.) – Situated Cognition: On Human Knowledge and Computer Representations (1997) Essays arguing that cognition cannot be isolated from context, critical for designing AI systems that learn from and adapt to changing environments.\nEric Margolis, Richard Samuels, \u0026 Stephen P. Stich (eds.) – The Oxford Handbook of Cognitive Science (2012) A comprehensive reference covering topics from perception and language to social cognition. I’ll use it as a “chemical map” to pinpoint deeper dives when needed.\n7. Mind, Human-AI Augmentation, and Prosthetics: Extending Cognitive Boundaries First Principles:\nExtended Mind Hypothesis: The idea that cognition isn’t confined to the brain but extends into tools, devices, and environments. Brain-Computer Interfaces (BCIs): Direct neural interfaces that allow two-way communication between brain and machine, blurring the line between biological and artificial cognition. Neuroprosthetics: Artificial devices, cochlear implants, limb prostheses, retinal implants, designed to restore or augment sensory and motor functions. Human-AI Symbiosis: Combining human intuition with AI’s computational power, “human in the loop” systems that enhance decision-making. Ethical \u0026 Philosophical Implications: What does it mean to be “posthuman”? How do agency, autonomy, and identity shift when our cognition is externally augmented? My Ten-Year Book Sequence:\nAndy Clark – Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence (2003) Argues that humans have always used tools to extend cognition, eyeglasses, writing, calculators. Clark shows how emerging technologies will further integrate with our minds.\nAndy Clark – Supersizing the Mind: Embodiment, Action, and Cognitive Extension (2008) Delves deeper into the Extended Mind Hypothesis, exploring how our environment and devices become part of our cognitive process. Essential for understanding how to design systems that feel “seamless” to users.\nN. Katherine Hayles – How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics (1999) A foundational work on how digital technologies reshape concepts of identity, embodiment, and consciousness. It provides a humanities perspective on posthumanism.\nJonathan Wolpaw \u0026 Elizabeth Winter Wolpaw (eds.) – Brain-Computer Interfaces: Principles and Practice (2012) An authoritative, technical overview of BCIs: signal acquisition, feature extraction, classification algorithms, and real-world applications. It bridges theory and practice in neural interfacing.\nKenneth W. Horch \u0026 Gurpreet S. Dhillon – Neuroprosthetics: Theory and Practice (2004) Covers the design principles, control strategies, and clinical applications of prosthetic devices that interface with the nervous system. It’s the go-to reference for anyone building artificial limbs or sensory implants.\nJoanne Morra \u0026 Matthew Fromberger – The Cyborg Experiments: The Extensions of the Body in the Media Age (2006) A collection of essays on how cultural, technological, and artistic practices shape our understanding of the “cyborg.” It situates prosthetics and augmentations in a broader cultural context.\nP.W. Singer – Wired for War: The Robotics Revolution and Conflict in the 21st Century (2009) Although focused on military applications, Singer’s analysis of robotics and prosthetics in modern warfare provides a sobering look at how augmentation can be weaponized, and raises ethical questions for civilian uses.\n8. Practical Applied AI \u0026 Applications: Bridging Theory and Production First Principles:\nPrototyping to Production: The lifecycle from research-code prototypes to scalable, maintainable deployments, data pipelines, model versioning, monitoring. Data Engineering Foundations: ETL patterns, streaming vs. batch ingestion, data validation, schema evolution. Model Management \u0026 MLOps: Version control, experiment tracking (MLflow, Kubeflow), reproducible training pipelines. Infrastructure \u0026 DevOps for AI: Containerization (Docker), orchestration (Kubernetes, Argo), CI/CD tailored to machine learning. Observability \u0026 Reliability: Monitoring for data drift, model performance, alerting, how to debug “silent” failures in production. My Ten-Year Book Sequence:\nAurélien Géron – Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (2nd ed., 2019) End-to-end machine learning pipelines in Python. I’ll work through each chapter’s exercises, covering clustering, CNNs, RNNs, and production workflows.\nMartin Kleppmann – Designing Data-Intensive Applications (2017) Core patterns for reliable, scalable data systems: streaming, replication, partitioning. Crucial for building AI pipelines that process terabytes of logs or sensor data.\nAndriy Burkov – Machine Learning Engineering (2020) Condenses practical advice on model deployment, monitoring, data pipelines, and team workflows. It fills the gap between “research” and “DevOps.”\nEmmanuel Ameisen – Building Machine Learning Powered Applications (2020) A step-by-step guide: ideation → data gathering → model training → deployment → maintenance. It emphasizes “why?” at each stage, so I don’t repeat past mistakes.\nAlice Zheng \u0026 Amanda Casari – Feature Engineering for Machine Learning (2018) A deep dive into transforming raw data into features that models can actually learn from. Often underestimated but critical for real-world performance.\nMark Treveil \u0026 Alok Shukla – MLOps: Model Management, Pipelines, and Practices at Scale (2021) Covers modern tooling (MLflow, Kubeflow, TFX) and best practices for versioning, testing, and monitoring. I’ll consult it once my basic pipelines work and I need to collaborate at scale.\nGeoffrey Hulten – Building Intelligent Systems: A Guide to Machine Learning Engineering (2018) Focuses on production concerns, latency, throughput, anomaly detection. Real-world case studies in e-commerce, fraud detection, and recommendation systems will inform my own designs.\n9. Engineering (Systems, Software, \u0026 Resilience): Turning Theory into Reliable Systems First Principles:\nAbstraction Hierarchy: From bits \u0026 bytes to data structures, algorithms, operating systems, and distributed systems, each layer builds on the one below. Design for Change: Embrace modularity, loose coupling, and patterns that anticipate future requirements, open for extension but closed for modification. Reliability \u0026 Resilience: Fault tolerance, redundancy, circuit breakers, backpressure, chaos engineering, design systems that survive unexpected failures. Scalability Patterns: Horizontal vs. vertical scaling, the CAP theorem, partitioning strategies, caching layers, load balancing. Observability \u0026 Feedback Loops: Logging, metrics, tracing, how to detect issues early and diagnose them quickly. Trade-Off Analysis: Consistency vs. availability, performance vs. maintainability, specialization vs. generality. My Ten-Year Book Sequence:\nAndrew Hunt \u0026 David Thomas – The Pragmatic Programmer: Your Journey to Mastery (20th Anniversary ed., 2019) Timeless principles of software craftsmanship. Each short chapter is an actionable lesson that will shape my coding habits from day one.\nErich Gamma, Richard Helm, Ralph Johnson, \u0026 John Vlissides – Design Patterns: Elements of Reusable Object-Oriented Software (1994) The classic “Gang of Four” patterns (Singleton, Observer, Factory, etc.). Recognizing and applying these patterns will become second nature by year three.\nRobert C. Martin – Clean Code: A Handbook of Agile Software Craftsmanship (2008) Best practices for writing readable, maintainable code. I’ll pair it with “Pragmatic Programmer” to ensure I write not only correct systems but also leave code cleaner than I found it.\nBetsy Beyer, Chris Jones, Jennifer Petoff, \u0026 Niall Richard Murphy (eds.) – Site Reliability Engineering: How Google Runs Production Systems (2016) Introduces SLIs, SLOs, error budgets, incident response, postmortems. Whenever I design a service that must run 24/7 at scale, I’ll refer to this.\nFrederick P. Brooks Jr. – The Mythical Man-Month: Essays on Software Engineering (Anniversary ed., 1995) Reflections on project management, communication overhead (Brooks’s Law), and realistic timelines. A required read whenever I’m estimating a large project.\nMartin Kleppmann – Designing Data-Intensive Applications (2017) (Appears earlier under applied AI, but its deeper systems-centric chapters, storage engines, message brokers, distributed consistency, demand another reading focused on reliability.)\nMichael T. Nygard – Release It!: Design and Deploy Production-Ready Software (2nd ed., 2018) Catalogs “Rustiness” patterns, circuit breakers, bulkheads, backpressure, dead-letter queues. It trains me to assume failures at every layer and design for graceful degradation.\nBrendan Gregg – Systems Performance: Enterprise and the Cloud (2nd ed., 2020) A deep dive into OS internals (CPU, memory, I/O, networking) and cloud performance tuning. I’ll use it to instrument and optimize systems at a low level, whether on bare-metal servers or in Kubernetes clusters.\nIntegrating Everything Over Ten Years Rather than treating these fields as isolated silos, the real power emerges when I juxtapose them. For example:\nSkimming Baddeley’s Working Memory alongside Gershon’s algorithms in Bishop’s Pattern Recognition and Machine Learning will sharpen my sense of how capacity limits in human cognition inform bounded-resource AI agents. Studying Williamson (epistemology) and then engaging with Bishop (probabilistic ML) will reveal how theory of knowledge underpins Bayesian modeling, what counts as “justified belief” when a Bayesian network updates its posterior. Combining Clark’s Supersizing the Mind (extended-mind theory) with Wolpaw \u0026 Wolpaw’s Brain-Computer Interfaces will help me design AI-powered augmentations that feel like natural extensions of the human user. Re-reading “Design Patterns” and “Designing Data-Intensive Applications” in Year 7 with fresh eyes, after I’ve internalized “The Extended Mind”, will let me question how domain-specific software patterns obscure or reveal underlying cognitive assumptions. Hence, after internalizing foundational texts (Years 1–4), I’ll begin rereading, this time from an integrative stance:\nYear 5: Revisit AI: A Modern Approach alongside Cognitive Psychology: A Student’s Handbook, annotating where symbolic planners parallel human problem-solving. Year 6–7: Reread Design Patterns and Clean Code with insights from Philosophical Investigations, questioning how our abstractions map onto real-world human intuitions. Years 8–9: Reexamine Site Reliability Engineering alongside The Cognitive Neurosciences, exploring how production-grade observability mirrors human metacognition. Year 10: Reflect on Clark’s Natural-Born Cyborgs and Hayles’ How We Became Posthuman, synthesizing an outlook on future AI-human integration in light of everything I’ve learned. How I’ll Stay on Track Annotate and Summarize: After every chapter, I’ll write a one-page “key principles” summary, note any questions raised, and jot down “potential applications” to keep concepts active in my mind.\nMonthly “Bridge Notes”: Every four weeks, I’ll draw explicit connections between recent readings. For example:\n“How does Baddeley’s model of working memory inform feature selection strategies in Bishop’s PRML?” “What does The Extended Mind reveal about building BCI systems covered in Wolpaw \u0026 Wolpaw’s book?” Hands-On Projects: Each year, I’ll commit to at least one side project that applies my learnings, whether building a toy ACT-R-inspired cognitive architecture in Python, prototyping a memory-augmented RL agent, or designing a BCI demo that translates motor imagery into simple commands.\nSpaced Review: I’ll use strategies from Make It Stick, spaced practice, interleaving, self-testing, to ensure I retain and integrate core ideas rather than merely “consuming.”\nYearly Reflection: At each anniversary of starting this journey, I’ll revisit my initial notes and reflect: Which concepts still feel fuzzy? Which books need a second reading? Which new questions have emerged?\nFinal Thoughts By following this structured, first-principles–based roadmap, I aim to become the “frontier engineer” and “thought leader” I envision, someone who seamlessly navigates between epistemology, symbolic systems, cognitive science, memory research, AI, human augmentation, and production-grade engineering. Over the next decade, this reading list will be my compass, ensuring that my learning is deep, integrated, and directly applicable to both research and real-world impact.\nIt’s not just a list of books; it’s a manifesto for continuous, intentional growth. Every time I pick up a volume, whether it’s Russell challenging my assumptions about knowledge, Clark reshaping how I think about tools, or Kleppmann revealing the internals of distributed logs, I’ll remember why I’m here: to build systems that think, remember, and adapt at the level of a thinking organism, and to do so with philosophical rigor, cognitive insight, and engineering excellence.\n","wordCount":"4156","inLanguage":"en","datePublished":"2023-01-01T12:00:00Z","dateModified":"2023-01-01T12:00:00Z","author":{"@type":"Person","name":"Archit Singh"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://archit15singh.github.io/posts/2023-01-01-my-reading-list/"},"publisher":{"@type":"Organization","name":"Archit's Space","logo":{"@type":"ImageObject","url":"https://archit15singh.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://archit15singh.github.io/ accesskey=h title="Archit's Space (Alt + H)">Archit's Space</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://archit15singh.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://archit15singh.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://archit15singh.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://archit15singh.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://archit15singh.github.io/posts/>Posts</a></div><h1 class=post-title>My Reading List for the next 10 years and Why</h1><div class=post-description>A decade-long, first-principles roadmap through epistemology, symbolic systems, cognition, memory, AI, human-AI augmentation, and engineering—mapping the foundational texts that will shape my journey as a systems thinker and AI engineer.</div><div class=post-meta><span title="2023-01-01 12:00:00 +0000 UTC">January 1, 2023</span>&nbsp;·&nbsp;20 min</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#my-reading-list-and-why aria-label="My Reading List and Why">My Reading List and Why</a><ul><li><a href=#why-im-doing-this aria-label="Why I’m Doing This">Why I’m Doing This</a></li><li><a href=#1-epistemology-laying-the-foundation-for-knowing aria-label="1. Epistemology: Laying the Foundation for “Knowing”">1. Epistemology: Laying the Foundation for “Knowing”</a></li><li><a href=#2-symbolic-systems-understanding-language-logic-and-computation aria-label="2. Symbolic Systems: Understanding Language, Logic, and Computation">2. Symbolic Systems: Understanding Language, Logic, and Computation</a></li><li><a href=#3-artificial-intelligence-from-search-to-deep-learning aria-label="3. Artificial Intelligence: From Search to Deep Learning">3. Artificial Intelligence: From Search to Deep Learning</a></li><li><a href=#4-cognition-how-minds-process-information aria-label="4. Cognition: How Minds Process Information">4. Cognition: How Minds Process Information</a></li><li><a href=#5-memory-from-molecules-to-minds aria-label="5. Memory: From Molecules to Minds">5. Memory: From Molecules to Minds</a></li><li><a href=#6-cognitive-systems--cognitive-science-integrating-mind-brain-and-environment aria-label="6. Cognitive Systems & Cognitive Science: Integrating Mind, Brain, and Environment">6. Cognitive Systems & Cognitive Science: Integrating Mind, Brain, and Environment</a></li><li><a href=#7-mind-human-ai-augmentation-and-prosthetics-extending-cognitive-boundaries aria-label="7. Mind, Human-AI Augmentation, and Prosthetics: Extending Cognitive Boundaries">7. Mind, Human-AI Augmentation, and Prosthetics: Extending Cognitive Boundaries</a></li><li><a href=#8-practical-applied-ai--applications-bridging-theory-and-production aria-label="8. Practical Applied AI & Applications: Bridging Theory and Production">8. Practical Applied AI & Applications: Bridging Theory and Production</a></li><li><a href=#9-engineering-systems-software--resilience-turning-theory-into-reliable-systems aria-label="9. Engineering (Systems, Software, & Resilience): Turning Theory into Reliable Systems">9. Engineering (Systems, Software, & Resilience): Turning Theory into Reliable Systems</a></li><li><a href=#integrating-everything-over-ten-years aria-label="Integrating Everything Over Ten Years">Integrating Everything Over Ten Years</a><ul><li><a href=#how-ill-stay-on-track aria-label="How I’ll Stay on Track">How I’ll Stay on Track</a></li></ul></li><li><a href=#final-thoughts aria-label="Final Thoughts">Final Thoughts</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=my-reading-list-and-why>My Reading List and Why<a hidden class=anchor aria-hidden=true href=#my-reading-list-and-why>#</a></h1><p>Over the past few years, I’ve found myself at the intersection of philosophy, cognitive science, and cutting-edge AI engineering. As someone who believes deeply in first-principles thinking, I realized I needed a coherent roadmap, a decade-long syllabus, if you will, that would guide both my intellectual growth and practical skill building. Instead of randomly picking books, I asked myself: <strong>What are the irreducible concepts I must master in epistemology, symbolic systems, cognition, memory, AI, cognitive systems, human-AI augmentation, and large-scale engineering?</strong> The answer became this reading list.</p><p>Below, I explain the meta-purpose behind this journey, then break down each domain into its core pillars and list the highest-impact books that will serve as stepping stones over the next ten years.</p><hr><h2 id=why-im-doing-this>Why I’m Doing This<a hidden class=anchor aria-hidden=true href=#why-im-doing-this>#</a></h2><ol><li><p><strong>Clarify My Intellectual Trajectory</strong>
I often remind myself: “Don’t accept surface-level explanations.” Whether I’m debugging a distributed system or diving into memory architectures for AI agents, I need to know why things work at a fundamental level. This reading list isn’t just a bibliography, it’s a scaffold that ensures every book I read builds on the ones before it.</p></li><li><p><strong>Align With Long-Term Goals</strong>
I’m targeting Stanford’s Symbolic Systems program and simultaneously leading AI-powered infrastructure projects. That means I need fluency in philosophical concepts like “justified belief” and hands-on expertise in deploying memory-augmented LLM pipelines. This dual pursuit of theory and practice shapes how I sequence these books.</p></li><li><p><strong>Bridge Theory and Practice</strong>
By approaching each field from first principles, I’ll see how epistemology informs probabilistic reasoning in AI or how cognitive-science insights shape my design of working-memory modules. I don’t want to treat theory and engineering as separate silos, I want them to feed into each other.</p></li><li><p><strong>Create an Executable Learning Plan</strong>
A decade seems long, but it can fly by if you wander aimlessly. By the end of year one, I should know the essentials of epistemology and basic symbolic computation. By year five, I’ll be integrating cognitive architectures with production-grade AI pipelines. By year ten, my hope is to ruminate on how self-reflexive AI agents can model their own “beliefs” and “memories.”</p></li></ol><hr><h2 id=1-epistemology-laying-the-foundation-for-knowing>1. Epistemology: Laying the Foundation for “Knowing”<a hidden class=anchor aria-hidden=true href=#1-epistemology-laying-the-foundation-for-knowing>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Knowledge vs. Belief vs. Justification:</strong> What distinguishes “knowing” from merely “believing”? How do we justify our claims?</li><li><strong>Sources of Knowledge:</strong> Empiricism (sense data), Rationalism (logical inference), Pragmatism (utility), Coherentism (network of beliefs).</li><li><strong>Limits of Knowledge:</strong> Skepticism (can we know anything at all?), fallibilism (our beliefs can always be mistaken), contextualism (knowledge claims shift with context).</li><li><strong>Epistemic Norms:</strong> How do we evaluate evidence? When is a belief “justified”? How do we handle defeaters and counterexamples?</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Bertrand Russell – <em>The Problems of Philosophy</em> (1912)</strong>
An accessible primer on “what is knowledge?” and why skepticism isn’t just a parlor game. Russell’s clarity lays the groundwork before diving into denser analyses.</p></li><li><p><strong>Robert Audi – <em>An Introduction to the Theory of Knowledge</em> (2003)</strong>
A systematic, classroom-style survey of belief, justification, and sources of knowledge. This text cements my grasp of key terminology and contrasts major schools of thought.</p></li><li><p><strong>Timothy Williamson – <em>Knowledge and Its Limits</em> (2000)</strong>
Challenges the classical “justified true belief” model, treating knowledge as a basic mental state. Williamson’s arguments push me to confront contemporary debates head-on.</p></li><li><p><strong>Jonathan Dancy & Ernest Sosa (eds.) – <em>Epistemology: Classic Problems and Contemporary Responses</em> (2010)</strong>
A curated anthology of landmark papers, Gettier, Goldman, Nozick, that each reframe a central problem. Reading them slowly, I’ll trace how foundational debates evolved.</p></li><li><p><strong>John Greco & Ernest Sosa (eds.) – <em>The Blackwell Guide to Epistemology</em> (1999)</strong>
Surveys subfields like social epistemology, virtue epistemology, and reliabilism. After Audi and Williamson, this volume shows how modern branches branched out.</p></li><li><p><strong>Abrol Fairweather & Linda Zagzebski (eds.) – <em>Virtue Epistemology: Essays on Epistemic Virtue and Responsibility</em> (1998)</strong>
Focuses on intellectual character traits, humility, curiosity, and how they shape knowledge production. This helps me connect theory to everyday inquiry.</p></li><li><p><strong>Bimal Krishna Matilal – <em>Philosophical Issues in Classical Indian Epistemology</em> (1986)</strong>
Broadens my perspective with non-Western pramāṇa theory: perception (pratyakṣa), inference (anumāna), testimony (śabda). I’ll learn alternative conceptions of knowledge.</p></li></ol><hr><h2 id=2-symbolic-systems-understanding-language-logic-and-computation>2. Symbolic Systems: Understanding Language, Logic, and Computation<a hidden class=anchor aria-hidden=true href=#2-symbolic-systems-understanding-language-logic-and-computation>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Symbolic Representation:</strong> How do discrete tokens, words, logical predicates, neural activations, encode meaning?</li><li><strong>Computation Over Symbols:</strong> The Church-Turing thesis, automata theory, and the notion that “cognition is computation.”</li><li><strong>Language as Structured Symbols:</strong> Syntax, semantics, and pragmatics; generative grammars (Chomsky) versus usage-based models.</li><li><strong>Cognition via Symbol Manipulation:</strong> Production systems (ACT-R, SOAR) and mental architectures that simulate symbol processing.</li><li><strong>Interdisciplinary Fusion:</strong> Blending philosophy, linguistics, computer science, psychology, and neuroscience into a cohesive framework.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Noam Chomsky – <em>Syntactic Structures</em> (1957)</strong>
Introduces generative grammar and formalizes how a finite set of rules can produce infinite sentences. Essential for modeling human language symbolically.</p></li><li><p><strong>Marvin Minsky – <em>Society of Mind</em> (1986)</strong>
Argues that mind emerges from interactions of simple agents. It bridges symbolic and connectionist views and shows how modular subunits create higher-level behavior.</p></li><li><p><strong>Michael Sipser – <em>Introduction to the Theory of Computation</em> (2nd ed., 2005)</strong>
Covers automata, formal languages, and Turing machines, ground zero for understanding “what can be computed.” Necessary before tackling computational models of cognition.</p></li><li><p><strong>Jay Friedenberg & Gordon Silverman – <em>Cognitive Science: An Introduction to the Science of the Mind</em> (3rd ed., 2017)</strong>
A broad survey of psychology, linguistics, AI, and neuroscience. It reveals how symbolic-systems thinkers integrate multiple perspectives.</p></li><li><p><strong>Daniel Solow – <em>How to Read and Do Proofs</em> (2012)</strong>
Teaches me to parse dense mathematical arguments and construct my own proofs. If I’m going to engage with formal semantics or computational complexity, these tools are indispensable.</p></li><li><p><strong>Ludwig Wittgenstein – <em>Philosophical Investigations</em> (1953)</strong>
Challenges the notion that meaning reduces to formal rule-following. Wittgenstein’s thought experiments force me to question how symbols “mean” anything in real life.</p></li><li><p><strong>John Haugeland (ed.) – <em>Mind Design II: Philosophy, Psychology, Artificial Intelligence</em> (1997)</strong>
A collection of essays on “designing” a mind in theory and practice. It aligns closely with Stanford’s Symbolic Systems teaching, weaving philosophy, AI, and psychology into a cohesive narrative.</p></li></ol><hr><h2 id=3-artificial-intelligence-from-search-to-deep-learning>3. Artificial Intelligence: From Search to Deep Learning<a hidden class=anchor aria-hidden=true href=#3-artificial-intelligence-from-search-to-deep-learning>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Search & Optimization:</strong> Many intelligent behaviors reduce to exploring a state space guided by heuristics.</li><li><strong>Knowledge Representation & Reasoning:</strong> Symbolic (logic, frames) vs. subsymbolic (neural embeddings); how we encode information.</li><li><strong>Machine Learning Fundamentals:</strong> Classical statistical models → representation learning → deep networks.</li><li><strong>Probabilistic Inference:</strong> Bayesian networks, Markov decision processes, modeling uncertainty in real environments.</li><li><strong>Reinforcement Learning & Planning:</strong> Agents learn via rewards or plan via tree search; the tension between model-based and model-free approaches.</li><li><strong>Embodiment & Robotics:</strong> Physical agents interacting with a world need perception, control, and real-time learning.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Stuart Russell & Peter Norvig – <em>Artificial Intelligence: A Modern Approach</em> (4th ed., 2020)</strong>
The canonical AI textbook. I’ll read it in sequence: search → logic → probabilistic models → learning → RL → robotics, building from basics to sophistication.</p></li><li><p><strong>Christopher Bishop – <em>Pattern Recognition and Machine Learning</em> (2006)</strong>
Focuses on probabilistic graphical models, kernel methods, and the EM algorithm. I need this statistical foundation before delving into neural networks.</p></li><li><p><strong>Ian Goodfellow, Yoshua Bengio, & Aaron Courville – <em>Deep Learning</em> (2016)</strong>
Provides a comprehensive overview of neural architectures, optimization, and theory. Reading this after Bishop sharpens my understanding of how classical methods evolved into deep nets.</p></li><li><p><strong>Sebastian Thrun, Wolfram Burgard, & Dieter Fox – <em>Probabilistic Robotics</em> (2005)</strong>
Embodied AI: SLAM, particle filters, and Kalman filters. If I ever build real-world agents, this book will be indispensable.</p></li><li><p><strong>Richard Sutton & Andrew Barto – <em>Reinforcement Learning: An Introduction</em> (2nd ed., 2018)</strong>
The definitive text on RL: dynamic programming, Monte Carlo methods, TD learning, function approximation. Crucial for constructing memory-augmented agents that solve sequential tasks.</p></li><li><p><strong>David Barber – <em>Bayesian Reasoning and Machine Learning</em> (2012)</strong>
Delves deeper into variational inference, sampling, and Bayesian methods. It complements probabilistic chapters in Russell & Norvig and Bishop.</p></li><li><p><strong>Toby Segaran – <em>Programming Collective Intelligence</em> (2007)</strong>
A hands-on guide to building recommenders, clustering algorithms, and classifiers in Python. I’ll use it to prototype quick, tangible demos, bridging theory and practice.</p></li></ol><hr><h2 id=4-cognition-how-minds-process-information>4. Cognition: How Minds Process Information<a hidden class=anchor aria-hidden=true href=#4-cognition-how-minds-process-information>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Information Processing Model:</strong> The brain is a system that takes input (perception), transforms it (attention, working memory), and outputs decisions or actions.</li><li><strong>Modularity vs. Distributed Processing:</strong> Are cognitive functions housed in specialized modules or emerging from distributed networks?</li><li><strong>Marr’s Tri-Level Analysis:</strong> Studying tasks at the computational (what problem is being solved?), algorithmic (how is it solved?), and implementational (how does neural hardware implement it?) levels.</li><li><strong>Mental Representations:</strong> Symbolic vs. connectionist, mental imagery vs. conceptual schemas.</li><li><strong>Decision-Making & Heuristics:</strong> How humans choose under bounded rationality, dual-process theories (System 1 vs. System 2).</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Michael Eysenck & Mark Keane – <em>Cognitive Psychology: A Student’s Handbook</em> (7th ed., 2015)</strong>
A thorough survey of perception, attention, memory, language, and reasoning. It provides the empirical groundwork to compare AI models against human benchmarks.</p></li><li><p><strong>Daniel Kahneman – <em>Thinking, Fast and Slow</em> (2011)</strong>
Explores System 1 (fast, intuitive) vs. System 2 (slow, deliberative) processes. Whenever I design algorithms that mimic, or correct, human decision-making, I’ll return to Kahneman.</p></li><li><p><strong>Steven Pinker – <em>How the Mind Works</em> (1997)</strong>
Uses evolutionary psychology to explain perception, language, and reasoning. It helps me see why certain AI architectures might reflect (or deliberately deviate from) our evolutionary heritage.</p></li><li><p><strong>David Marr – <em>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</em> (1982)</strong>
Marr’s classic on vision breaks down image processing at computational, algorithmic, and implementational levels. It sets a template for analyzing any cognitive task.</p></li><li><p><strong>Daniel Reisberg – <em>Cognition: Exploring the Science of the Mind</em> (6th ed., 2018)</strong>
A modern, experiment-driven account of memory, attention, language, and problem solving. Its up-to-date findings guide my understanding of how to build AI that aligns with human tendencies.</p></li><li><p><strong>Gary Klein – <em>Sources of Power: How People Make Decisions</em> (1998)</strong>
Examines real-world experts (firefighters, pilots) making split-second decisions. If my future agents need to operate under stress, Klein’s work teaches how humans succeed, or fail, in critical scenarios.</p></li><li><p><strong>Michael S. Gazzaniga (ed.) – <em>The Cognitive Neurosciences</em> (6th ed., 2018)</strong>
An anthology on neural mechanisms underlying cognitive processes: attention networks, working-memory circuits, decision-making pathways. I’ll use it as a reference whenever I delve into brain-inspired approaches.</p></li></ol><hr><h2 id=5-memory-from-molecules-to-minds>5. Memory: From Molecules to Minds<a hidden class=anchor aria-hidden=true href=#5-memory-from-molecules-to-minds>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Encoding → Storage → Retrieval:</strong> The stages of memory: input gets held in working memory, consolidates into long-term storage, and later gets retrieved.</li><li><strong>Long-Term Memory Types:</strong> Declarative (episodic vs. semantic) vs. nondeclarative (procedural, priming).</li><li><strong>Neural Mechanisms:</strong> Hippocampus vs. neocortex, synaptic plasticity (LTP/LTD), and how memories stabilize over time.</li><li><strong>Working Memory Models:</strong> Baddeley’s multicomponent model, phonological loop, visuospatial sketchpad, central executive.</li><li><strong>Forgetting & Interference:</strong> Theories on decay, retrieval failure, proactive vs. retroactive interference.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Larry Squire & Eric Kandel – <em>Memory: From Mind to Molecules</em> (1999)</strong>
Connects cognitive behavioral experiments with cellular and molecular neuroscience. Early on, I’ll map high-level memory phenomena onto biological substrates.</p></li><li><p><strong>Alan Baddeley – <em>Working Memory</em> (2007)</strong>
Details the multicomponent model and its experimental basis. Essential for designing AI “memory buffers” that approximate human capacity constraints.</p></li><li><p><strong>Daniel Schacter – <em>The Seven Sins of Memory</em> (2001)</strong>
Describes real-world memory failures, transience, misattribution, suggestibility. When building memory-driven agents, I’ll refer to this to anticipate analogous “AI pitfalls.”</p></li><li><p><strong>Alan Baddeley & Michael Anderson – <em>Human Memory: Theory and Practice</em> (2nd ed., 2000)</strong>
Combines theory with practical applications (e.g., spaced repetition). I’ll mine it for strategies (mnemonics, retrieval practice) that inform how to manage retention in large contexts.</p></li><li><p><strong>John O’Keefe & Lynn Nadel – <em>The Hippocampus as a Cognitive Map</em> (1978)</strong>
Introduces place cells and spatial memory. This work inspires me to think about embedding “episodic context” in an agent’s memory system.</p></li><li><p><strong>Mark Bear, Barry Connors, & Michael Paradiso – <em>Learning and Memory: From Brain to Behavior</em> (2nd ed., 2006)</strong>
Integrates molecular/cellular mechanisms with overt behavior. I’ll align my ML architectures (e.g., synaptic-like weight updates) with real neural processes.</p></li><li><p><strong>Peter C. Brown, Henry L. Roediger III, & Mark A. McDaniel – <em>Make It Stick: The Science of Successful Learning</em> (2014)</strong>
Distills memory research into practical strategies (retrieval practice, spacing). Since I need to internalize dozens of books over ten years, I’ll apply these techniques to retain and interleave concepts effectively.</p></li></ol><hr><h2 id=6-cognitive-systems--cognitive-science-integrating-mind-brain-and-environment>6. Cognitive Systems & Cognitive Science: Integrating Mind, Brain, and Environment<a hidden class=anchor aria-hidden=true href=#6-cognitive-systems--cognitive-science-integrating-mind-brain-and-environment>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Interdisciplinary Integration:</strong> Cognitive science blends computer science (formal models), psychology (behavioral experiments), neuroscience (brain data), linguistics (language structure), and philosophy (conceptual analysis).</li><li><strong>Computational Models of Cognition:</strong> Architectures like ACT-R, SOAR, and connectionist neural networks; each embodies a different theory of how mental processes operate.</li><li><strong>Embodied & Situated Cognition:</strong> Cognition arises from continuous interaction with the environment, mind is not a “brain in a vat.”</li><li><strong>Cognitive Architectures:</strong> Unified frameworks (ACT-R, Soar) that simulate broad cognitive tasks under a single theoretical umbrella.</li><li><strong>Human-Computer Interaction & AI Integration:</strong> How humans and machines co-adapt, key for designing AI tools that “think” in human-useful ways.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Neil Stillings, Steven Weisler, & Christopher Hauff – <em>Cognitive Science: An Introduction</em> (4th ed., 2018)</strong>
A broad survey of core topics (perception, language, reasoning) with computational emphasis. Early on, I’ll use it to see how all the pieces connect.</p></li><li><p><strong>John R. Anderson – <em>How Can the Human Mind Occur in the Physical Universe?</em> (2007)</strong>
A deep dive into ACT-R: how modules (memory retrieval, problem solving) fit together. I’ll study it to understand how a working cognitive architecture is constructed.</p></li><li><p><strong>Robert D. Rupert – <em>The Distributed Mind: Achieving High-Level Cognition through Interactions between the Brain, Body, and World</em> (2004)</strong>
Argues for embodied cognition, the mind extends beyond neurons into the body and world. It shapes how I think about building agents that “live” in an environment.</p></li><li><p><strong>Philippe Jacobs & Michael Jordan (eds.) – <em>An Introduction to Connectionist Models of Cognition</em> (1993)</strong>
A collection of neural network models showing how subsymbolic processing can simulate cognitive tasks. It helps me compare symbolic (ACT-R) vs. subsymbolic approaches.</p></li><li><p><strong>Klaus Mainzer – <em>Cognitive Systems and Neuroscience: The Conceptual Foundations of Neurophysics</em> (2002)</strong>
Explores mathematical and philosophical foundations of modeling cognitive processes in physical systems. I’ll focus on chapters showing how high-level cognitive theories map onto neural substrates.</p></li><li><p><strong>Philip R. Cohen, Jerry A. Good, & James G. Pollack (eds.) – <em>Situated Cognition: On Human Knowledge and Computer Representations</em> (1997)</strong>
Essays arguing that cognition cannot be isolated from context, critical for designing AI systems that learn from and adapt to changing environments.</p></li><li><p><strong>Eric Margolis, Richard Samuels, & Stephen P. Stich (eds.) – <em>The Oxford Handbook of Cognitive Science</em> (2012)</strong>
A comprehensive reference covering topics from perception and language to social cognition. I’ll use it as a “chemical map” to pinpoint deeper dives when needed.</p></li></ol><hr><h2 id=7-mind-human-ai-augmentation-and-prosthetics-extending-cognitive-boundaries>7. Mind, Human-AI Augmentation, and Prosthetics: Extending Cognitive Boundaries<a hidden class=anchor aria-hidden=true href=#7-mind-human-ai-augmentation-and-prosthetics-extending-cognitive-boundaries>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Extended Mind Hypothesis:</strong> The idea that cognition isn’t confined to the brain but extends into tools, devices, and environments.</li><li><strong>Brain-Computer Interfaces (BCIs):</strong> Direct neural interfaces that allow two-way communication between brain and machine, blurring the line between biological and artificial cognition.</li><li><strong>Neuroprosthetics:</strong> Artificial devices, cochlear implants, limb prostheses, retinal implants, designed to restore or augment sensory and motor functions.</li><li><strong>Human-AI Symbiosis:</strong> Combining human intuition with AI’s computational power, “human in the loop” systems that enhance decision-making.</li><li><strong>Ethical & Philosophical Implications:</strong> What does it mean to be “posthuman”? How do agency, autonomy, and identity shift when our cognition is externally augmented?</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Andy Clark – <em>Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence</em> (2003)</strong>
Argues that humans have always used tools to extend cognition, eyeglasses, writing, calculators. Clark shows how emerging technologies will further integrate with our minds.</p></li><li><p><strong>Andy Clark – <em>Supersizing the Mind: Embodiment, Action, and Cognitive Extension</em> (2008)</strong>
Delves deeper into the Extended Mind Hypothesis, exploring how our environment and devices become part of our cognitive process. Essential for understanding how to design systems that feel “seamless” to users.</p></li><li><p><strong>N. Katherine Hayles – <em>How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics</em> (1999)</strong>
A foundational work on how digital technologies reshape concepts of identity, embodiment, and consciousness. It provides a humanities perspective on posthumanism.</p></li><li><p><strong>Jonathan Wolpaw & Elizabeth Winter Wolpaw (eds.) – <em>Brain-Computer Interfaces: Principles and Practice</em> (2012)</strong>
An authoritative, technical overview of BCIs: signal acquisition, feature extraction, classification algorithms, and real-world applications. It bridges theory and practice in neural interfacing.</p></li><li><p><strong>Kenneth W. Horch & Gurpreet S. Dhillon – <em>Neuroprosthetics: Theory and Practice</em> (2004)</strong>
Covers the design principles, control strategies, and clinical applications of prosthetic devices that interface with the nervous system. It’s the go-to reference for anyone building artificial limbs or sensory implants.</p></li><li><p><strong>Joanne Morra & Matthew Fromberger – <em>The Cyborg Experiments: The Extensions of the Body in the Media Age</em> (2006)</strong>
A collection of essays on how cultural, technological, and artistic practices shape our understanding of the “cyborg.” It situates prosthetics and augmentations in a broader cultural context.</p></li><li><p><strong>P.W. Singer – <em>Wired for War: The Robotics Revolution and Conflict in the 21st Century</em> (2009)</strong>
Although focused on military applications, Singer’s analysis of robotics and prosthetics in modern warfare provides a sobering look at how augmentation can be weaponized, and raises ethical questions for civilian uses.</p></li></ol><hr><h2 id=8-practical-applied-ai--applications-bridging-theory-and-production>8. Practical Applied AI & Applications: Bridging Theory and Production<a hidden class=anchor aria-hidden=true href=#8-practical-applied-ai--applications-bridging-theory-and-production>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Prototyping to Production:</strong> The lifecycle from research-code prototypes to scalable, maintainable deployments, data pipelines, model versioning, monitoring.</li><li><strong>Data Engineering Foundations:</strong> ETL patterns, streaming vs. batch ingestion, data validation, schema evolution.</li><li><strong>Model Management & MLOps:</strong> Version control, experiment tracking (MLflow, Kubeflow), reproducible training pipelines.</li><li><strong>Infrastructure & DevOps for AI:</strong> Containerization (Docker), orchestration (Kubernetes, Argo), CI/CD tailored to machine learning.</li><li><strong>Observability & Reliability:</strong> Monitoring for data drift, model performance, alerting, how to debug “silent” failures in production.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Aurélien Géron – <em>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow</em> (2nd ed., 2019)</strong>
End-to-end machine learning pipelines in Python. I’ll work through each chapter’s exercises, covering clustering, CNNs, RNNs, and production workflows.</p></li><li><p><strong>Martin Kleppmann – <em>Designing Data-Intensive Applications</em> (2017)</strong>
Core patterns for reliable, scalable data systems: streaming, replication, partitioning. Crucial for building AI pipelines that process terabytes of logs or sensor data.</p></li><li><p><strong>Andriy Burkov – <em>Machine Learning Engineering</em> (2020)</strong>
Condenses practical advice on model deployment, monitoring, data pipelines, and team workflows. It fills the gap between “research” and “DevOps.”</p></li><li><p><strong>Emmanuel Ameisen – <em>Building Machine Learning Powered Applications</em> (2020)</strong>
A step-by-step guide: ideation → data gathering → model training → deployment → maintenance. It emphasizes “why?” at each stage, so I don’t repeat past mistakes.</p></li><li><p><strong>Alice Zheng & Amanda Casari – <em>Feature Engineering for Machine Learning</em> (2018)</strong>
A deep dive into transforming raw data into features that models can actually learn from. Often underestimated but critical for real-world performance.</p></li><li><p><strong>Mark Treveil & Alok Shukla – <em>MLOps: Model Management, Pipelines, and Practices at Scale</em> (2021)</strong>
Covers modern tooling (MLflow, Kubeflow, TFX) and best practices for versioning, testing, and monitoring. I’ll consult it once my basic pipelines work and I need to collaborate at scale.</p></li><li><p><strong>Geoffrey Hulten – <em>Building Intelligent Systems: A Guide to Machine Learning Engineering</em> (2018)</strong>
Focuses on production concerns, latency, throughput, anomaly detection. Real-world case studies in e-commerce, fraud detection, and recommendation systems will inform my own designs.</p></li></ol><hr><h2 id=9-engineering-systems-software--resilience-turning-theory-into-reliable-systems>9. Engineering (Systems, Software, & Resilience): Turning Theory into Reliable Systems<a hidden class=anchor aria-hidden=true href=#9-engineering-systems-software--resilience-turning-theory-into-reliable-systems>#</a></h2><p><strong>First Principles:</strong></p><ul><li><strong>Abstraction Hierarchy:</strong> From bits & bytes to data structures, algorithms, operating systems, and distributed systems, each layer builds on the one below.</li><li><strong>Design for Change:</strong> Embrace modularity, loose coupling, and patterns that anticipate future requirements, open for extension but closed for modification.</li><li><strong>Reliability & Resilience:</strong> Fault tolerance, redundancy, circuit breakers, backpressure, chaos engineering, design systems that survive unexpected failures.</li><li><strong>Scalability Patterns:</strong> Horizontal vs. vertical scaling, the CAP theorem, partitioning strategies, caching layers, load balancing.</li><li><strong>Observability & Feedback Loops:</strong> Logging, metrics, tracing, how to detect issues early and diagnose them quickly.</li><li><strong>Trade-Off Analysis:</strong> Consistency vs. availability, performance vs. maintainability, specialization vs. generality.</li></ul><p><strong>My Ten-Year Book Sequence:</strong></p><ol><li><p><strong>Andrew Hunt & David Thomas – <em>The Pragmatic Programmer: Your Journey to Mastery</em> (20th Anniversary ed., 2019)</strong>
Timeless principles of software craftsmanship. Each short chapter is an actionable lesson that will shape my coding habits from day one.</p></li><li><p><strong>Erich Gamma, Richard Helm, Ralph Johnson, & John Vlissides – <em>Design Patterns: Elements of Reusable Object-Oriented Software</em> (1994)</strong>
The classic “Gang of Four” patterns (Singleton, Observer, Factory, etc.). Recognizing and applying these patterns will become second nature by year three.</p></li><li><p><strong>Robert C. Martin – <em>Clean Code: A Handbook of Agile Software Craftsmanship</em> (2008)</strong>
Best practices for writing readable, maintainable code. I’ll pair it with “Pragmatic Programmer” to ensure I write not only correct systems but also leave code cleaner than I found it.</p></li><li><p><strong>Betsy Beyer, Chris Jones, Jennifer Petoff, & Niall Richard Murphy (eds.) – <em>Site Reliability Engineering: How Google Runs Production Systems</em> (2016)</strong>
Introduces SLIs, SLOs, error budgets, incident response, postmortems. Whenever I design a service that must run 24/7 at scale, I’ll refer to this.</p></li><li><p><strong>Frederick P. Brooks Jr. – <em>The Mythical Man-Month: Essays on Software Engineering</em> (Anniversary ed., 1995)</strong>
Reflections on project management, communication overhead (Brooks’s Law), and realistic timelines. A required read whenever I’m estimating a large project.</p></li><li><p><strong>Martin Kleppmann – <em>Designing Data-Intensive Applications</em> (2017)</strong>
(Appears earlier under applied AI, but its deeper systems-centric chapters, storage engines, message brokers, distributed consistency, demand another reading focused on reliability.)</p></li><li><p><strong>Michael T. Nygard – <em>Release It!: Design and Deploy Production-Ready Software</em> (2nd ed., 2018)</strong>
Catalogs “Rustiness” patterns, circuit breakers, bulkheads, backpressure, dead-letter queues. It trains me to assume failures at every layer and design for graceful degradation.</p></li><li><p><strong>Brendan Gregg – <em>Systems Performance: Enterprise and the Cloud</em> (2nd ed., 2020)</strong>
A deep dive into OS internals (CPU, memory, I/O, networking) and cloud performance tuning. I’ll use it to instrument and optimize systems at a low level, whether on bare-metal servers or in Kubernetes clusters.</p></li></ol><hr><h2 id=integrating-everything-over-ten-years>Integrating Everything Over Ten Years<a hidden class=anchor aria-hidden=true href=#integrating-everything-over-ten-years>#</a></h2><p>Rather than treating these fields as isolated silos, the real power emerges when I <strong>juxtapose</strong> them. For example:</p><ul><li>Skimming Baddeley’s <em>Working Memory</em> alongside Gershon’s algorithms in Bishop’s <em>Pattern Recognition and Machine Learning</em> will sharpen my sense of how capacity limits in human cognition inform bounded-resource AI agents.</li><li>Studying Williamson (epistemology) and then engaging with Bishop (probabilistic ML) will reveal how <strong>theory of knowledge</strong> underpins <strong>Bayesian modeling</strong>, what counts as “justified belief” when a Bayesian network updates its posterior.</li><li>Combining Clark’s <em>Supersizing the Mind</em> (extended-mind theory) with Wolpaw & Wolpaw’s <em>Brain-Computer Interfaces</em> will help me design AI-powered augmentations that feel like natural extensions of the human user.</li><li>Re-reading “Design Patterns” and “Designing Data-Intensive Applications” in Year 7 with fresh eyes, after I’ve internalized “The Extended Mind”, will let me question how domain-specific software patterns obscure or reveal underlying cognitive assumptions.</li></ul><p>Hence, after internalizing foundational texts (Years 1–4), I’ll begin <strong>rereading</strong>, this time from an integrative stance:</p><ul><li><strong>Year 5:</strong> Revisit <em>AI: A Modern Approach</em> alongside <em>Cognitive Psychology: A Student’s Handbook</em>, annotating where symbolic planners parallel human problem-solving.</li><li><strong>Year 6–7:</strong> Reread <em>Design Patterns</em> and <em>Clean Code</em> with insights from <em>Philosophical Investigations</em>, questioning how our abstractions map onto real-world human intuitions.</li><li><strong>Years 8–9:</strong> Reexamine <em>Site Reliability Engineering</em> alongside <em>The Cognitive Neurosciences</em>, exploring how production-grade observability mirrors human metacognition.</li><li><strong>Year 10:</strong> Reflect on Clark’s <em>Natural-Born Cyborgs</em> and Hayles’ <em>How We Became Posthuman</em>, synthesizing an outlook on future AI-human integration in light of everything I’ve learned.</li></ul><hr><h3 id=how-ill-stay-on-track>How I’ll Stay on Track<a hidden class=anchor aria-hidden=true href=#how-ill-stay-on-track>#</a></h3><ol><li><p><strong>Annotate and Summarize:</strong> After every chapter, I’ll write a one-page “key principles” summary, note any questions raised, and jot down “potential applications” to keep concepts active in my mind.</p></li><li><p><strong>Monthly “Bridge Notes”:</strong> Every four weeks, I’ll draw explicit connections between recent readings. For example:</p><ul><li>“How does Baddeley’s model of working memory inform feature selection strategies in Bishop’s PRML?”</li><li>“What does <em>The Extended Mind</em> reveal about building BCI systems covered in Wolpaw & Wolpaw’s book?”</li></ul></li><li><p><strong>Hands-On Projects:</strong> Each year, I’ll commit to at least one side project that applies my learnings, whether building a toy ACT-R-inspired cognitive architecture in Python, prototyping a memory-augmented RL agent, or designing a BCI demo that translates motor imagery into simple commands.</p></li><li><p><strong>Spaced Review:</strong> I’ll use strategies from <em>Make It Stick</em>, spaced practice, interleaving, self-testing, to ensure I retain and integrate core ideas rather than merely “consuming.”</p></li><li><p><strong>Yearly Reflection:</strong> At each anniversary of starting this journey, I’ll revisit my initial notes and reflect: Which concepts still feel fuzzy? Which books need a second reading? Which new questions have emerged?</p></li></ol><hr><h2 id=final-thoughts>Final Thoughts<a hidden class=anchor aria-hidden=true href=#final-thoughts>#</a></h2><p>By following this structured, first-principles–based roadmap, I aim to become the “frontier engineer” and “thought leader” I envision, someone who seamlessly navigates between epistemology, symbolic systems, cognitive science, memory research, AI, human augmentation, and production-grade engineering. Over the next decade, this reading list will be my compass, ensuring that my learning is deep, integrated, and directly applicable to both research and real-world impact.</p><p>It’s not just a list of books; it’s a manifesto for continuous, intentional growth. Every time I pick up a volume, whether it’s Russell challenging my assumptions about knowledge, Clark reshaping how I think about tools, or Kleppmann revealing the internals of distributed logs, I’ll remember <strong>why</strong> I’m here: to build systems that think, remember, and adapt at the level of a thinking organism, and to do so with philosophical rigor, cognitive insight, and engineering excellence.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://archit15singh.github.io/tags/reading/>Reading</a></li></ul><nav class=paginav><a class=next href=https://archit15singh.github.io/posts/2022-01-01-who-am-i/><span class=title>Next Page »</span><br><span>Who Am I?</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on twitter" href="https://twitter.com/intent/tweet/?text=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why&amp;url=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f&amp;hashtags=Reading"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f&amp;title=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why&amp;summary=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why&amp;source=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on reddit" href="https://reddit.com/submit?url=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f&title=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on whatsapp" href="https://api.whatsapp.com/send?text=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why%20-%20https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg>
</a><a target=_blank rel="noopener noreferrer" aria-label="share My Reading List for the next 10 years and Why on telegram" href="https://telegram.me/share/url?text=My%20Reading%20List%20for%20the%20next%2010%20years%20and%20Why&amp;url=https%3a%2f%2farchit15singh.github.io%2fposts%2f2023-01-01-my-reading-list%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><div class=container><div class="content has-text-centered"><p><strong>Archit's Space</strong> - Sharing knowledge one post at a time.<br>Crafted with ❤️ by Archit Singh</a>.<br>Connect with me on
<a href=https://github.com/archit15singh target=_blank>GitHub</a>,
<a href=https://www.linkedin.com/in/archit15singh target=_blank>LinkedIn</a>,
and <a href=https://twitter.com/archit15singh target=_blank>Twitter</a>.</p></div></div></footer><script data-goatcounter=https://architsingh.goatcounter.com/count async src=//gc.zgo.at/count.js></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>